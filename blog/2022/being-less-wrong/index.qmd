---
title: The Art of Being Less Wrong
subtitle: An Introduction to Bayesian Model Averaged Marginal Effects
pagetitle: The Art of Being Less Wrong
date: 2022-05-24
description: "This post provides an introduction to Bayesian Model Averaging and Model Averaged Marginal Effects with Stan, `{brms}`, and `{marginaleffects}`"
categories: [R, Bayesian Statistics, Causal Inference, Marginal Effects, Stan, Logit, Model Averaging]
license: All content in this post is made available for public use under a Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) License.
image: figs/preview-fig.png
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  cache = FALSE,
  warning = FALSE,
  message = FALSE,
  comment = ' ',
  fig.path = 'figs/',
  fig.align = "center",
  fig.process = function(x) {
    x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
    if (file.rename(x, x2))
      x2
    else
      x
  }
)

## Load the necessary libraries
pacman::p_load(
  "tidyverse",
  "arrow",
  "data.table",
  "ggdag",
  "dagitty",
  "patchwork",
  "posterior",
  "kableExtra",
  install = FALSE
)
```

::: callout-important
### Work in Progress

This is a draft post and under is currently under development. I have not proofread any of the contents herein

:::

# Introduction

George E. P. Box famously described the problem of model development in statistics and related fields by noting, 
*all models are wrong, but some models are useful* [-@Box1976]. That is, all models are necessarily simplifications 
ofa much more complex reality and statistics is by no means an algorithmic truth generating process because no 
model can ever be true in the pure sense of the word. Yet, this at times underappreciated reality does not render 
all models useless but rather implies the goal of those who practice statistics in its various forms is to 
develop and identify models that are useful in a never ending quest to be less wrong. In this post I introduce an 
approach to this task that has been the subject of my own dissertation work on the use of Bayesian Model Averaging 
(BMA) to account for uncertainty in model specification when estimating average marginal effects in non-linear 
regression models. 

::: a 
I introduce what I call a Bayesian Model Averaged Marginal Effect (BMAME) in the context of logistic regression 
models in political science and illustrate how to obtain BMAMEs in a straightforward manner using the 
`{marginaleffects}` R package, which thanks to Vincent Arel-Bundock's assistance supports model averaged or
stacked average marginal effects for any model fit with the Stan interface `{brms}` 
[@ArelBundock2022a; @Burkner2017; @Burkner2018]. I also provide a more general demonstration in Stan that makes
the method easily applicable in Python and high dimensional settings. Although I focus here on models that include 
only population-level effects, recent feature additions to `{marginaleffects}` now make it possible to obtain
BMAMEs from more complex hierarchical models and I will cover such applications in a subsequent post.
::: 

# Bayesian Model Averaging in Political Science

Although Bayesian Model Averaging was introduced to political science more than two decades ago 
by @Bartels1997, cases of its use in political science remain rare and are largely confined to the topic 
of political methodology [@Juhl2019; @Cranmer2015; @Montgomery2010].[^1] This presents something of a 
problem given the numerous studies demonstrating the dangers of tossing a large number of likely correlated 
predictors into a regression model [@Achen2005; @Clarke2005; @Clarke2009; @Montgomery2018]; the reality that 
if we wish to adjudicate between two or more competing theories, comparing coefficients in a single model is 
generally insufficient to accomplish such a task [@Imai2011; @Clarke2007; @Hollenbach2020]; and the difficulty 
of assessing what we truly known about political phenomenon that results from an obsession with "statistical 
significance" and precise answers to poorly defined questions [@Ward2010; @Schrodt2014; @Lundberg2021]. 

[^1]: For a recent application of BMA in the context of instrument selection see @Rozenas2019.

::: a 
In contrast to the advice of @Montgomery2010 who suggest "BMA is best used as a subsequent robustness 
check to show that our inferences are not overly sensitive to plausible variations in model specification" 
(266), I argue here that model averaging can and should be used as far more than a robustness check if for
no other reason than because a model-wise mixture distribution for our paramter of intertest is almost 
certainly more informative than a point estimate from a single model specification. Indeed, BMA provides
one of the few natural and intuitive ways of resolving some of the issues outlined in the preceding 
paragraph, particularly as it pertains to the evaluation of non-nested theoretical models, while also
exhibiting a lower false positive rate than alternative approaches [@Pluemper2018]. 

BMA is particularly useful in the context of effect estimates from models that employ non-linear link 
functions such as logit which impede the ability to compare coefficient estimates across different 
model specifications in any meaningful way [@Mood2009; @Daniel2020], a point I will return to later in
this post. This section provides a brief explanation of BMA and its relation to what I term model 
averaged marginal effects before proceeding to a discussion of how the procedure is implemented.
::: 

## Bayesian Model Comparison and Model Averaging

Consider a simple case in which we have a set of $\mathcal{M}$ models, each of which characterizes a 
possible representation of some unknown data generation process. Although it remains common practice 
in applied political science to select a single model based on a largely arbitrary fit statistic 
(i.e., AIC, $\chi^{2}$, or whatever people are getting a p-value from this week), such an approach is 
problematic since it ignores the uncertainty inherent in the process of model specification. Rather 
than selecting a single model and consequently placing an implicit zero prior on 
**every other possible model specification you could have considered but did not**, Bayesian Model 
Averaging and its analogues provide a means of averaging across several possible, potentially 
non-nested, model specifications and accounting for the uncertainty associated with doing so.

::: a 
Imagine we wish to adjudicate between two competing theoretical models in the set of candidate models 
$\mathcal{M}$. The posterior odds of model $i$ relative to an alternative $k$ can be expressed as
:::

$$
\underbrace{\frac{\Pr(\mathcal{M}_{i} \, | \, y)}{\Pr(\mathcal{M}_{k} \, | \, y)}}_{\mathrm{Posterior~Odds}} = \underbrace{\frac{p(y \, | \, \mathcal{M}_{i})}{p(y \, | \, \mathcal{M}_{k})}}_{\mathrm{Bayes~Factor}} \times \underbrace{\frac{\pi(\mathcal{M}_{i})}{\pi(\mathcal{M}_{k})}}_{\mathrm{Model~Prior}}
$$ {#eq-posterior-odds} 

where $\pi(\mathcal{M})$ is the prior probability of model $i$ over model $k$ and $p(y \,|\, \mathcal{M})$ 
is the marginal likelihood of the observed data under each of the candidate models such that

$$
\underbrace{p(y \,|\, \mathcal{M})}_{\mathrm{Marginal~Likelihood}} = \int\underbrace{p(y \,|\, \theta,\, \mathcal{M})}_{\mathrm{Likelihood}} \, \underbrace{\pi(\theta \,|\, \mathcal{M})}_{\mathrm{Prior}}d\theta
$$ {#eq-marginal-likelihood}

::: a 
Given our prior assumptions about how likely the observed data are to have arisen from each model in the set 
$\mathcal{M}$, the result of equation @eq-posterior-odds is the posterior odds of model $i$ compared to model 
$k$ and thus captures the relative probability that model $\mathcal{M_{i}}$ represents the true data generation 
process compared to the plausible alternative $\mathcal{M_{k}}$. We can easily extend this example to the setting 
in which $\mathcal{M_{k}}$ is a set of plausible competing models of size $k > 2$, in which case the posterior 
model probability of the $i^{th}$ model relative to each of the alternatives $k$ is
:::

$$
\Pr(\mathcal{M}_{i} \,|\, y) = \frac{p(y \, | \, \mathcal{M}_{i}) \, \cdot \, \pi(\mathcal{M}_{i})}{\displaystyle\sum^{\mathcal{m}}_{k=1} p(y \, | \, \mathcal{M}_{k}) \, \cdot \, \pi(\mathcal{M}_{k})}
$$ {#eq-posterior-probability} 

which provides the posterior model probability of model $i$ relative to each of the alternative candidate 
specifications $k$. Applying equation @eq-posterior-probability to each model in the set under consideration 
yields a vector of relative posterior model probabilities of length $m$ which may be used as either posterior 
probability weights as in the case of Bayesian Model Averaging or for the estimation of posterior inclusion 
probabilities.

::: a 
In the context of model averaging, we can take draws from the posterior predictive distribution of each model 
containing a given parameter of interest proportional to its posterior probability weight obtained from equation 
@eq-posterior-probability. This yields a model-wise mixture representing a weighted average of the posterior 
predictive distribution for some parameter such as a regression coefficient for a linear model or as I outline 
below, an average marginal effect or probability contrast for models that employ a non-linear link function. 
::: 

## Model Averaged Marginal Effects

Average marginal effects are ubquitous in the social sciences though, as 
[Andrew Heiss nicely illustrates](https://www.andrewheiss.com/blog/2022/05/20/marginalia/), the term average 
marginal effect is often used ambiguously and in the context of more complex models, the terms marginal and
conditional [tend to be a source of additional confusion](https://www.andrewheiss.com/blog/2022/11/29/conditional-marginal-marginaleffects/). 
In the case of a simple population-level linear model with a Gaussian likelihood and identity link function, 
the model averaged marginal effect is equivalent to the posterior distribution of the model averaged 
coefficient $\beta$ which can be expressed as

$$
\mathbb{E}(\beta \, | \, y) = \sum_{i=1}^{m}\Pr(\mathcal{M}_{i} \, | \, y) \cdot \mathbb{E}(\beta\, |\, \mathcal{M}_{i}, \, y) \quad \forall \quad i \in \{1, 2,\dots, m\}
$$ {#eq-bma-population} 

where $\Pr(\mathcal{M}_{i} ~ | ~ y)$ represent the posterior model probability and 
$\mathbb{E}(\beta ~|~ \mathcal{M}_{i}, ~ y)$ is the expected value of some parameter $\beta$ 
conditional on the observed data and some model specification for each model $i$ in the set of 
models under consideration $m$ [@Montgomery2010].

::: a
For probability models such as logit, and other commonly used formulations for modeling
discrete responses, this simple closed form solution does not exist nor is there any meaningful
way to interpret the coefficients of these models as efffect size estimates--a reality that unfortunately 
remains quite widely misunderstood [@Mood2009; @Daniel2020]. As a general principle, any model more
complex than a simple linear regression can only be meaningfully interpreted in terms of the predictions
it generates [@Long2018], which in the case of logistic regression simply means applying the inverse 
logistic function to obtain predicted probabilities which we can then use to estimate contrasts or average 
marginal effects [@Norton2019]. Letting $\mathrm{Y}$ represent a binary outcome, $\mathrm{X}$ a continuous 
exposure or treatment of interest, and $\mathrm{Z}$ a matrix of observed confounders we can express the 
average marginal effect as
:::

$$
\begin{align}
\mathrm{AME}\Delta_{j} &= \int \frac{\mathbb{E}[\Pr(\mathrm{Y}_{ij} = 1 | \mathrm{X}_{ij} = \mathrm{x}_{ij} + h, \mathrm{Z}_{ij}) ~-~ \Pr(\mathrm{Y}_{ij} = 1 | \mathrm{X}_{ij} = \mathrm{x}_{ij}, \mathrm{Z}_{ij})]d\mathrm{Z}}{h} \\
\end{align}
$$ {#eq-logit-continuous-ame} 

which provided a sufficiently small value of $h$, yields a reasonable approximation of the partial derivative 
and provides a posterior distribution for the average effect of an instantaneous change in $\mathrm{X}$ on the
probability scale similar to what one obtains in linear regression.[^2]

[^2]: In the case of an interval exposure, it may make more sense to estimate a marginal effect at each unique or representative value of $\mathrm{X}$ to better capture non-linearities.

::: a
Similarly, for a binary treatment of interest we apply the Bayesian g-formula to obtain the average marginal 
effect of $\mathrm{X}$ on the probability of $\mathrm{Y}$ as shown in equation @eq-logit-binary-ame.
:::
$$
\begin{align}
\mathrm{AME}\Delta_{j} &= \int \mathbb{E}[\Pr(\mathrm{Y}_{ij} = 1 ~ | ~ \mathrm{X}_{ij} = 1, \mathrm{Z}_{ij}) ~-~ \Pr(\mathrm{Y}_{ij} = 1 ~ | ~ \mathrm{X}_{ij} = 0, \mathrm{Z}_{ij})]d\mathrm{Z} \\
\end{align}
$$ {#eq-logit-binary-ame}

Equations @eq-logit-continuous-ame and @eq-logit-binary-ame make clear that we are averaging over the confounder 
distribution $\mathrm{Z}$ rather than holding it constant at some fixed value [@Oganisian2020; @Keil2017]. 
This point is an important one because in binary outcome models such as logit and probit, holding $\mathrm{Z}$ 
constant at some fixed value such as the mean corresponds to **an entirely different estimand** [@Hanmer2012].
The AME is a population-averaged quantity, corresponding to the population average treatment effect and these
two quantities can produce very different results under fairly general conditions because **they do not answer 
the same question**.

::: a
From here it is straightforward to obtain a model averaged marginal effect estimate for a binary outcome model
such as logit. Given marginal predictions for each model $k$ in the set $m$, we can apply equation @eq-logit-bmame
to obtain the posterior distribution of average marginal effects for each model.
:::

$$
\mathrm{BMAME}\Delta_{j} = \sum_{k=1}^{m} \Pr(\mathcal{M}_{k} | y)\cdot\mathrm{AME}\Delta_{k,j}
$$ {#eq-logit-bmame} 

This yields a model-wise mixture distribution representing the weighted average of the marginal effects
estimates and has much broad applicability to scenarios common in the social sciences and beyond.

## BMA, Stacking, and the Open-$\mathcal{M}$ Problem

While traditional marginal likelihood-based Bayesian modeling is a powerful and principled technique for 
dealing with uncertainty in the process of model specification and selection, it is nevertheless imperfect 
owing in part to the fact that its validity rests upon the closed $\mathcal{M}$ assumption implicit in 
equation @eq-posterior-probability. In the open $\mathcal{M}$ setting where the true model is not among 
those in the set of candidate models under consideration, as will generally be the case in any social 
science application, traditional BMA is flawed and estimated effects based on posterior probability 
weights are likely to be biased [@Hollenbach2020; @Yao2018]. This problem arises from the fact that 
marginal-likelihood based posterior probability weights for each model $i \in \mathcal{M}$ correspond to 
the posterior probability that a given model captures the true data generation process and in the social 
sciences this is unlikely to ever be the case since, by definition, *all models are wrong*. 

::: a
In the open $\mathcal{M}$ setting, traditional BMA will still assign each model some probability but since by 
definition $\sum_{i=1}^{m}\Pr(\mathcal{M}_{i} ~|~ y) = 1$, these weights no longer have a valid 
interpretation in terms of the posterior probability a given model is true. Although this does not render marginal 
likelihood based model averaging useless and it may often make more sense to think about model specification and 
selection as a probabilistic process aimed at identifying the most likely model conditional on the set of models 
under consideration [@Hinne2020], it is advisable to assess whether our substantive conclusions are sensitive to 
potential violations of the closed $\mathcal{M}$ assumption. This once again underscores the fact that statistics is 
not an mechanistic truth generating process and *there is no magic*. It also underscores the need to think in more 
local terms--rather than asking *is this model true* we generally want to know *the probability $\mathrm{X}$ 
belongs to the true data generation process*.

An alternative but still properly Bayesian approach aimed at addressing these potential flaws in traditional BMA 
is cross-validation based stacking [@Yao2018]. In contrast to traditional BMA, stacking 
and pseudo-BMA weights are constructed based on the relative expectation of the posterior predictive 
density [@Hollenbach2020; @Yao2018]. These approaches to estimating model weights do not rely upon the closed 
$\mathcal{M}$ assumption, and thus provide a way of either avoiding it altogether or relaxing it as a robustness 
check on the posterior probability weights, albeit while answering a fundamentally different question more appropriate 
for an open $\mathcal{M}$ world.[^4]
::: 

[^4]: For a more formal discussion of stacking and pseudo-BMA weights, I direct readers to @Yao2018.

# Implementation and Illustration

Once we have decided how to obtain the model weights--whether using marginal likelihood or cross-validation based 
stacking--the `{marginaleffects}` package provides the necessary functionality to handle everything else for us 
thanks to the feature-rich support for various approaches to averaging across posterior distributions provided by 
`{brms}`. To obtain the BMAME for a given parameter while accounting for the uncertainty in the model specifications, 
version 0.5.0 and higher of `{marginaleffects}` allows users to specify the argument `type = "average"` in their
call to either `marginaleffects::marginaleffects` or `marginaleffects::comparisons` for objects of class `brmsfit`
along with any additional arguments to be passed down to `pp_average` such as the type of weights to estimate, or 
alternatively a numeric vector of pre-estimated weights which is usually the more computationally efficient option 
and the approach I take in the applied example below. For those cases not covered by the marginal effects 
implementation, I also provide an illustration via R and Stan that should be fairly straightforward to convert to 
other languages as necessary.

::: a
To demonstrate this functionality, I draw on an example loosely adapted from part of my dissertation research in 
which I examine how the active participation of women in rebel groups during wartime shapes the political calculus 
of former combatant groups at war's end--in short, I expect rebel groups where women participated in combat roles 
during wartime are *more likely* to form political parties and participate in post-conflict elections. Note this 
demonstration is not comprehensive and only illustrates one aspect of how BMAMEs might be applied in practice. 
However, as far as `{marginaleffects}` functionality is concerned, the general workflow is identical regardless.
:::

# References