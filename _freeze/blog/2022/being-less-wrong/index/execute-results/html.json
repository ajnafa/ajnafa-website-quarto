{
  "hash": "983c53c05f98c284e6856593d3893adf",
  "result": {
    "markdown": "---\ntitle: The Art of Being Less Wrong\nsubtitle: An Introduction to Bayesian Model Averaged Marginal Effects\npagetitle: The Art of Being Less Wrong\ndate: 2022-05-24\ndescription: \"This post provides an introduction to Bayesian Model Averaging and Model Averaged Marginal Effects with Stan, `{brms}`, and `{marginaleffects}`\"\ncategories: [R, Bayesian Statistics, Causal Inference, Marginal Effects, Stan, Logit, Model Averaging]\nlicense: All content in this post is made available for public use under a Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) License.\nimage: figs/preview-fig.png\n---\n\n\n\n\n::: callout-important\n### Work in Progress\n\nThis is a draft post and under is currently under development. I have not proofread any of the contents herein\n\n:::\n\n# Introduction\n\nGeorge E. P. Box famously described the problem of model development in statistics and related fields by noting, \n*all models are wrong, but some models are useful* [-@Box1976]. That is, all models are necessarily simplifications \nofa much more complex reality and statistics is by no means an algorithmic truth generating process because no \nmodel can ever be true in the pure sense of the word. Yet, this at times underappreciated reality does not render \nall models useless but rather implies the goal of those who practice statistics in its various forms is to \ndevelop and identify models that are useful in a never ending quest to be less wrong. In this post I introduce an \napproach to this task that has been the subject of my own dissertation work on the use of Bayesian Model Averaging \n(BMA) to account for uncertainty in model specification when estimating average marginal effects in non-linear \nregression models. \n\n::: a \nI introduce what I call a Bayesian Model Averaged Marginal Effect (BMAME) in the context of logistic regression \nmodels in political science and illustrate how to obtain BMAMEs in a straightforward manner using the \n`{marginaleffects}` R package, which thanks to Vincent Arel-Bundock's assistance supports model averaged or\nstacked average marginal effects for any model fit with the Stan interface `{brms}` \n[@ArelBundock2022a; @Burkner2017; @Burkner2018]. I also provide a more general demonstration in Stan that makes\nthe method easily applicable in Python and high dimensional settings. Although I focus here on models that include \nonly population-level effects, recent feature additions to `{marginaleffects}` now make it possible to obtain\nBMAMEs from more complex hierarchical models and I will cover such applications in a subsequent post.\n::: \n\n# Bayesian Model Averaging in Political Science\n\nAlthough Bayesian Model Averaging was introduced to political science more than two decades ago \nby @Bartels1997, cases of its use in political science remain rare and are largely confined to the topic \nof political methodology [@Juhl2019; @Cranmer2015; @Montgomery2010].[^1] This presents something of a \nproblem given the numerous studies demonstrating the dangers of tossing a large number of likely correlated \npredictors into a regression model [@Achen2005; @Clarke2005; @Clarke2009; @Montgomery2018]; the reality that \nif we wish to adjudicate between two or more competing theories, comparing coefficients in a single model is \ngenerally insufficient to accomplish such a task [@Imai2011; @Clarke2007; @Hollenbach2020]; and the difficulty \nof assessing what we truly known about political phenomenon that results from an obsession with \"statistical \nsignificance\" and precise answers to poorly defined questions [@Ward2010; @Schrodt2014; @Lundberg2021]. \n\n[^1]: For a recent application of BMA in the context of instrument selection see @Rozenas2019.\n\n::: a \nIn contrast to the advice of @Montgomery2010 who suggest \"BMA is best used as a subsequent robustness \ncheck to show that our inferences are not overly sensitive to plausible variations in model specification\" \n(266), I argue here that model averaging can and should be used as far more than a robustness check if for\nno other reason than because a model-wise mixture distribution for our paramter of intertest is almost \ncertainly more informative than a point estimate from a single model specification. Indeed, BMA provides\none of the few natural and intuitive ways of resolving some of the issues outlined in the preceding \nparagraph, particularly as it pertains to the evaluation of non-nested theoretical models, while also\nexhibiting a lower false positive rate than alternative approaches [@Pluemper2018]. \n\nBMA is particularly useful in the context of effect estimates from models that employ non-linear link \nfunctions such as logit which impede the ability to compare coefficient estimates across different \nmodel specifications in any meaningful way [@Mood2009; @Daniel2020], a point I will return to later in\nthis post. This section provides a brief explanation of BMA and its relation to what I term model \naveraged marginal effects before proceeding to a discussion of how the procedure is implemented.\n::: \n\n## Bayesian Model Comparison and Model Averaging\n\nConsider a simple case in which we have a set of $\\mathcal{M}$ models, each of which characterizes a \npossible representation of some unknown data generation process. Although it remains common practice \nin applied political science to select a single model based on a largely arbitrary fit statistic \n(i.e., AIC, $\\chi^{2}$, or whatever people are getting a p-value from this week), such an approach is \nproblematic since it ignores the uncertainty inherent in the process of model specification. Rather \nthan selecting a single model and consequently placing an implicit zero prior on \n**every other possible model specification you could have considered but did not**, Bayesian Model \nAveraging and its analogues provide a means of averaging across several possible, potentially \nnon-nested, model specifications and accounting for the uncertainty associated with doing so.\n\n::: a \nImagine we wish to adjudicate between two competing theoretical models in the set of candidate models \n$\\mathcal{M}$. The posterior odds of model $i$ relative to an alternative $k$ can be expressed as\n:::\n\n$$\n\\underbrace{\\frac{\\Pr(\\mathcal{M}_{i} \\, | \\, y)}{\\Pr(\\mathcal{M}_{k} \\, | \\, y)}}_{\\mathrm{Posterior~Odds}} = \\underbrace{\\frac{p(y \\, | \\, \\mathcal{M}_{i})}{p(y \\, | \\, \\mathcal{M}_{k})}}_{\\mathrm{Bayes~Factor}} \\times \\underbrace{\\frac{\\pi(\\mathcal{M}_{i})}{\\pi(\\mathcal{M}_{k})}}_{\\mathrm{Model~Prior}}\n$$ {#eq-posterior-odds} \n\nwhere $\\pi(\\mathcal{M})$ is the prior probability of model $i$ over model $k$ and $p(y \\,|\\, \\mathcal{M})$ \nis the marginal likelihood of the observed data under each of the candidate models such that\n\n$$\n\\underbrace{p(y \\,|\\, \\mathcal{M})}_{\\mathrm{Marginal~Likelihood}} = \\int\\underbrace{p(y \\,|\\, \\theta,\\, \\mathcal{M})}_{\\mathrm{Likelihood}} \\, \\underbrace{\\pi(\\theta \\,|\\, \\mathcal{M})}_{\\mathrm{Prior}}d\\theta\n$$ {#eq-marginal-likelihood}\n\n::: a \nGiven our prior assumptions about how likely the observed data are to have arisen from each model in the set \n$\\mathcal{M}$, the result of equation @eq-posterior-odds is the posterior odds of model $i$ compared to model \n$k$ and thus captures the relative probability that model $\\mathcal{M_{i}}$ represents the true data generation \nprocess compared to the plausible alternative $\\mathcal{M_{k}}$. We can easily extend this example to the setting \nin which $\\mathcal{M_{k}}$ is a set of plausible competing models of size $k > 2$, in which case the posterior \nmodel probability of the $i^{th}$ model relative to each of the alternatives $k$ is\n:::\n\n$$\n\\Pr(\\mathcal{M}_{i} \\,|\\, y) = \\frac{p(y \\, | \\, \\mathcal{M}_{i}) \\, \\cdot \\, \\pi(\\mathcal{M}_{i})}{\\displaystyle\\sum^{\\mathcal{m}}_{k=1} p(y \\, | \\, \\mathcal{M}_{k}) \\, \\cdot \\, \\pi(\\mathcal{M}_{k})}\n$$ {#eq-posterior-probability} \n\nwhich provides the posterior model probability of model $i$ relative to each of the alternative candidate \nspecifications $k$. Applying equation @eq-posterior-probability to each model in the set under consideration \nyields a vector of relative posterior model probabilities of length $m$ which may be used as either posterior \nprobability weights as in the case of Bayesian Model Averaging or for the estimation of posterior inclusion \nprobabilities.\n\n::: a \nIn the context of model averaging, we can take draws from the posterior predictive distribution of each model \ncontaining a given parameter of interest proportional to its posterior probability weight obtained from equation \n@eq-posterior-probability. This yields a model-wise mixture representing a weighted average of the posterior \npredictive distribution for some parameter such as a regression coefficient for a linear model or as I outline \nbelow, an average marginal effect or probability contrast for models that employ a non-linear link function. \n::: \n\n## Model Averaged Marginal Effects\n\nAverage marginal effects are ubquitous in the social sciences though, as \n[Andrew Heiss nicely illustrates](https://www.andrewheiss.com/blog/2022/05/20/marginalia/), the term average \nmarginal effect is often used ambiguously and in the context of more complex models, the terms marginal and\nconditional [tend to be a source of additional confusion](https://www.andrewheiss.com/blog/2022/11/29/conditional-marginal-marginaleffects/). \nIn the case of a simple population-level linear model with a Gaussian likelihood and identity link function, \nthe model averaged marginal effect is equivalent to the posterior distribution of the model averaged \ncoefficient $\\beta$ which can be expressed as\n\n$$\n\\mathbb{E}(\\beta \\, | \\, y) = \\sum_{i=1}^{m}\\Pr(\\mathcal{M}_{i} \\, | \\, y) \\cdot \\mathbb{E}(\\beta\\, |\\, \\mathcal{M}_{i}, \\, y) \\quad \\forall \\quad i \\in \\{1, 2,\\dots, m\\}\n$$ {#eq-bma-population} \n\nwhere $\\Pr(\\mathcal{M}_{i} ~ | ~ y)$ represent the posterior model probability and \n$\\mathbb{E}(\\beta ~|~ \\mathcal{M}_{i}, ~ y)$ is the expected value of some parameter $\\beta$ \nconditional on the observed data and some model specification for each model $i$ in the set of \nmodels under consideration $m$ [@Montgomery2010].\n\n::: a\nFor probability models such as logit, and other commonly used formulations for modeling\ndiscrete responses, this simple closed form solution does not exist nor is there any meaningful\nway to interpret the coefficients of these models as efffect size estimates--a reality that unfortunately \nremains quite widely misunderstood [@Mood2009; @Daniel2020]. As a general principle, any model more\ncomplex than a simple linear regression can only be meaningfully interpreted in terms of the predictions\nit generates [@Long2018], which in the case of logistic regression simply means applying the inverse \nlogistic function to obtain predicted probabilities which we can then use to estimate contrasts or average \nmarginal effects [@Norton2019]. Letting $\\mathrm{Y}$ represent a binary outcome, $\\mathrm{X}$ a continuous \nexposure or treatment of interest, and $\\mathrm{Z}$ a matrix of observed confounders we can express the \naverage marginal effect as\n:::\n\n$$\n\\begin{align}\n\\mathrm{AME}\\Delta_{j} &= \\int \\frac{\\mathbb{E}[\\Pr(\\mathrm{Y}_{ij} = 1 | \\mathrm{X}_{ij} = \\mathrm{x}_{ij} + h, \\mathrm{Z}_{ij}) ~-~ \\Pr(\\mathrm{Y}_{ij} = 1 | \\mathrm{X}_{ij} = \\mathrm{x}_{ij}, \\mathrm{Z}_{ij})]d\\mathrm{Z}}{h} \\\\\n\\end{align}\n$$ {#eq-logit-continuous-ame} \n\nwhich provided a sufficiently small value of $h$, yields a reasonable approximation of the partial derivative \nand provides a posterior distribution for the average effect of an instantaneous change in $\\mathrm{X}$ on the\nprobability scale similar to what one obtains in linear regression.[^2]\n\n[^2]: In the case of an interval exposure, it may make more sense to estimate a marginal effect at each unique or representative value of $\\mathrm{X}$ to better capture non-linearities.\n\n::: a\nSimilarly, for a binary treatment of interest we apply the Bayesian g-formula to obtain the average marginal \neffect of $\\mathrm{X}$ on the probability of $\\mathrm{Y}$ as shown in equation @eq-logit-binary-ame.\n:::\n$$\n\\begin{align}\n\\mathrm{AME}\\Delta_{j} &= \\int \\mathbb{E}[\\Pr(\\mathrm{Y}_{ij} = 1 ~ | ~ \\mathrm{X}_{ij} = 1, \\mathrm{Z}_{ij}) ~-~ \\Pr(\\mathrm{Y}_{ij} = 1 ~ | ~ \\mathrm{X}_{ij} = 0, \\mathrm{Z}_{ij})]d\\mathrm{Z} \\\\\n\\end{align}\n$$ {#eq-logit-binary-ame}\n\nEquations @eq-logit-continuous-ame and @eq-logit-binary-ame make clear that we are averaging over the confounder \ndistribution $\\mathrm{Z}$ rather than holding it constant at some fixed value [@Oganisian2020; @Keil2017]. \nThis point is an important one because in binary outcome models such as logit and probit, holding $\\mathrm{Z}$ \nconstant at some fixed value such as the mean corresponds to **an entirely different estimand** [@Hanmer2012].\nThe AME is a population-averaged quantity, corresponding to the population average treatment effect and these\ntwo quantities can produce very different results under fairly general conditions because **they do not answer \nthe same question**.\n\n::: a\nFrom here it is straightforward to obtain a model averaged marginal effect estimate for a binary outcome model\nsuch as logit. Given marginal predictions for each model $k$ in the set $m$, we can apply equation @eq-logit-bmame\nto obtain the posterior distribution of average marginal effects for each model.\n:::\n\n$$\n\\mathrm{BMAME}\\Delta_{j} = \\sum_{k=1}^{m} \\Pr(\\mathcal{M}_{k} | y)\\cdot\\mathrm{AME}\\Delta_{k,j}\n$$ {#eq-logit-bmame} \n\nThis yields a model-wise mixture distribution representing the weighted average of the marginal effects\nestimates and has much broad applicability to scenarios common in the social sciences and beyond.\n\n## BMA, Stacking, and the Open-$\\mathcal{M}$ Problem\n\nWhile traditional marginal likelihood-based Bayesian modeling is a powerful and principled technique for \ndealing with uncertainty in the process of model specification and selection, it is nevertheless imperfect \nowing in part to the fact that its validity rests upon the closed $\\mathcal{M}$ assumption implicit in \nequation @eq-posterior-probability. In the open $\\mathcal{M}$ setting where the true model is not among \nthose in the set of candidate models under consideration, as will generally be the case in any social \nscience application, traditional BMA is flawed and estimated effects based on posterior probability \nweights are likely to be biased [@Hollenbach2020; @Yao2018]. This problem arises from the fact that \nmarginal-likelihood based posterior probability weights for each model $i \\in \\mathcal{M}$ correspond to \nthe posterior probability that a given model captures the true data generation process and in the social \nsciences this is unlikely to ever be the case since, by definition, *all models are wrong*. \n\n::: a\nIn the open $\\mathcal{M}$ setting, traditional BMA will still assign each model some probability but since by \ndefinition $\\sum_{i=1}^{m}\\Pr(\\mathcal{M}_{i} ~|~ y) = 1$, these weights no longer have a valid \ninterpretation in terms of the posterior probability a given model is true. Although this does not render marginal \nlikelihood based model averaging useless and it may often make more sense to think about model specification and \nselection as a probabilistic process aimed at identifying the most likely model conditional on the set of models \nunder consideration [@Hinne2020], it is advisable to assess whether our substantive conclusions are sensitive to \npotential violations of the closed $\\mathcal{M}$ assumption. This once again underscores the fact that statistics is \nnot an mechanistic truth generating process and *there is no magic*. It also underscores the need to think in more \nlocal terms--rather than asking *is this model true* we generally want to know *the probability $\\mathrm{X}$ \nbelongs to the true data generation process*.\n\nAn alternative but still properly Bayesian approach aimed at addressing these potential flaws in traditional BMA \nis cross-validation based stacking [@Yao2018]. In contrast to traditional BMA, stacking \nand pseudo-BMA weights are constructed based on the relative expectation of the posterior predictive \ndensity [@Hollenbach2020; @Yao2018]. These approaches to estimating model weights do not rely upon the closed \n$\\mathcal{M}$ assumption, and thus provide a way of either avoiding it altogether or relaxing it as a robustness \ncheck on the posterior probability weights, albeit while answering a fundamentally different question more appropriate \nfor an open $\\mathcal{M}$ world.[^4]\n::: \n\n[^4]: For a more formal discussion of stacking and pseudo-BMA weights, I direct readers to @Yao2018.\n\n# Implementation and Illustration\n\nOnce we have decided how to obtain the model weights--whether using marginal likelihood or cross-validation based \nstacking--the `{marginaleffects}` package provides the necessary functionality to handle everything else for us \nthanks to the feature-rich support for various approaches to averaging across posterior distributions provided by \n`{brms}`. To obtain the BMAME for a given parameter while accounting for the uncertainty in the model specifications, \nversion 0.5.0 and higher of `{marginaleffects}` allows users to specify the argument `type = \"average\"` in their\ncall to either `marginaleffects::marginaleffects` or `marginaleffects::comparisons` for objects of class `brmsfit`\nalong with any additional arguments to be passed down to `pp_average` such as the type of weights to estimate, or \nalternatively a numeric vector of pre-estimated weights which is usually the more computationally efficient option \nand the approach I take in the applied example below. For those cases not covered by the marginal effects \nimplementation, I also provide an illustration via R and Stan that should be fairly straightforward to convert to \nother languages as necessary.\n\n::: a\nTo demonstrate this functionality, I draw on an example loosely adapted from part of my dissertation research in \nwhich I examine how the active participation of women in rebel groups during wartime shapes the political calculus \nof former combatant groups at war's end--in short, I expect rebel groups where women participated in combat roles \nduring wartime are *more likely* to form political parties and participate in post-conflict elections. Note this \ndemonstration is not comprehensive and only illustrates one aspect of how BMAMEs might be applied in practice. \nHowever, as far as `{marginaleffects}` functionality is concerned, the general workflow is identical regardless.\n:::\n\n# References",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}