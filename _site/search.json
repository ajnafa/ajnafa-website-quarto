[
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "A. Jordan Nafa",
    "section": "",
    "text": "I am a Quantitative Social Scientist and Teaching Fellow in the Department of Political Science at the University of North Texas where I apply Bayesian inference and computational statistics to examine how contextual factors shape individuals’ attitudes, decisions, and behavior. I have five years’ experience working both independently and in collaboration with colleagues to model data and provide insights necessary to answer research questions. My core skills include research design, causal inference, quasi-experimental methods, advanced data analytics in R, Stan, and Python, survey research, and an expertise in applied Bayesian statistics. I also currently teach undergraduate courses in applied causal inference for quantitative political research and have previously taught courses in American political institutions and behavior."
  },
  {
    "objectID": "about/index.html#experience",
    "href": "about/index.html#experience",
    "title": "A. Jordan Nafa",
    "section": "Experience",
    "text": "Experience\n\n\nQuantitative Social Scientist\nUniversity of North Texas\n\n\nAug 2018 - Present\nDenton, TX\n\n\n\n\nTeaching Fellow\nUniversity of North Texas\n\n\nOct 2021 - Present\nDenton, TX\n\n\n\n\nResearch Assistant\nTexas Woman’s University\n\n\nFeb 2018 - Aug 2018\nDenton, TX"
  },
  {
    "objectID": "about/index.html#education",
    "href": "about/index.html#education",
    "title": "A. Jordan Nafa",
    "section": "Education",
    "text": "Education\n\n\nUniversity of North Texas\nPhD in Political Science\n\n\nAug 2018 - Present\nDenton, TX\n\n\n\n\nTexas Woman’s University\nBachelor of Science in Political Science\n\n\nAug 2014 - Aug 2018\nDenton, TX"
  },
  {
    "objectID": "blog/2022/statistical-adjustment-interpretation/index.html",
    "href": "blog/2022/statistical-adjustment-interpretation/index.html",
    "title": "These Aren’t the Effects You’re Looking For",
    "section": "",
    "text": "\\[\n\\newcommand{\\indep}{\\perp \\!\\!\\! \\perp}\n\\]"
  },
  {
    "objectID": "blog/2022/statistical-adjustment-interpretation/index.html#introduction",
    "href": "blog/2022/statistical-adjustment-interpretation/index.html#introduction",
    "title": "These Aren’t the Effects You’re Looking For",
    "section": "Introduction",
    "text": "Introduction\nWestreich and Greenland (2013) originally coined the term Table 2 fallacy to describe the common practice of presenting confounders included in a regression model alongside the treatment or exposure of interest in Table 2 of an article and tendency of researchers to interpret the coefficients for said confounders as total effect estimates. Subsequent work has further highlighted the problem in political science (Keele, Stevenson, and Elwert 2019), economics (Hünermund and Louw 2020), and sociology (Lundberg, Johnson, and Stewart 2021). The consequences of this practice are often pernicious, with subsequent studies treating inappropriately reported estimates as theoretically informative quantities despite having no valid interpretation in their original context and readers drawing incorrect conclusions with no empirical basis. Despite efforts to discourage the practice and some steps in the right direction, the Table 2 fallacy remains an often committed mistake by researchers across a diverse range of fields.\n\nThis blog post provides an overview of the logic of statistical control, the fallacy of mutual adjustment, and a simulation-based illustration of correct and incorrect approaches to the interpretation of multivariable regression models in the social sciences. In this post I take as my starting point two primary assumptions about research in the quantitative social sciences. First, I assume the goal of any scientific study that does not explicitly state otherwise is to evaluate some proposed theoretical explanation for an assumed causal relationship. Research in the contemporary social sciences is primarily interested in evaluating theoretical claims about causal processes and the practice of relying on euphamisms and weasel words to avoid saying cause and effect while still heavily implying the existance of a causal relationship does not change this reality (Hernán 2018; Samii 2016).\nSecond, I assume that any theoretical process from which testable implications can be derived may be represented in the form of a directed acyclic graph (DAG). While DAGs may be more common in some fields than others, the ability to express an assumed theoretical process in the form of a non-parameteric causal graph is a necessary condition for specifying a model of the process and estimating a causal relationship. If this is not possible, it generally implies the researcher is confused about what exactly they are trying to accomplish and does not have a properly defined research question (Lundberg, Johnson, and Stewart 2021).\nNeither of these assumptions should be taken to imply all research in the social sciences must be concerned with evaluating causal claims. Indeed, there is value in mere description and exploratory research that highlights interesting questions and provides useful context for causal analyses or theory building (Gerring 2004, 2012). It is, however, necessary to be explicit about our inferential goals and the question we are attempting to answer in a given study. After all, the foundation of social scientific inquiry and quantitative research more broadly lies in the art of providing vague answers to precise questions."
  },
  {
    "objectID": "blog/2022/statistical-adjustment-interpretation/index.html#the-logic-of-regression-adjustment",
    "href": "blog/2022/statistical-adjustment-interpretation/index.html#the-logic-of-regression-adjustment",
    "title": "These Aren’t the Effects You’re Looking For",
    "section": "The Logic of Regression Adjustment",
    "text": "The Logic of Regression Adjustment\nFollowing Rubin (1974, 1976, 2005), a causal effect is defined as the difference in potential outcomes. Letting \\(Y_{i}\\) represent the observed outcome for each unit \\(i \\in \\{1,2,\\dots, N\\}\\), \\(X_{i}\\) the observed treatment status for the \\(i^{th}\\) unit, and \\(Z\\) some set of measured confounders that influence both the treatment assignment mechanism and the observed outcome we can express the causal effect of a binary treatment as\n\\[\nY_{i}(X_{i} = 1, Z_{i}) - Y_{i}(X_{i} = 0, Z_{i})\n\\tag{1}\\]\nAs equation 1 makes clear, a causal effect is the difference between the value of the outcome we observe under the treatment status \\(X_{i} = 1\\) for unit \\(i\\) and the counterfactual and value of the outcome we would have observed under \\(X_{i} = 0\\).\n\nIn an ideal world, we could estimate unit-level treatment effects. In practice, however, since for each unit \\(i\\) we can observe the potential outcome \\(Y_{i}(X_{i} = 1)\\) or \\(Y_{i}(X_{i} = 0)\\) but it is logically impossible to observe both. As such we typically take as our estimand the treatment effect in some subset of the population. For example, in a Bayesian framework we can express the posterior distribution of the population average treatment effect as\n\\[\n\\mathrm{PATE} = \\int\\mathrm{E[Y_{ij}(X_{ij} = 1, Z_{ij})]} - \\mathrm{E[Y_{ij}(X_{ij} = 0, Z_{ij})]}d\\mathrm{Z_{ij}}\n\\tag{2}\\]\nGiven a set of identifying assumptions, equation 2 yields an estimate for the posterior distribution of the expected change in the outcome if all of the units received the treatment compared to what we would have observed if no unit was treated (Oganisian and Roy 2020). We can represent this process in the form of a DAG as shown in figure 1, which implies conditional on the set of measured confounders \\(Z = \\{z_{1},z_{2}, z_{3}\\}\\), the treatment assigment is as good as random thus identifying the causal path \\(X \\longrightarrow Y\\). There are several strategies one might take to close the backdoor confounding paths \\(X \\longleftarrow Z \\longrightarrow Y\\) including though not necessarily limited to random assignment of the treatment, propensity-score based methods, and regression adjustment. Since the topic of this post is statistical control, however, I limit my focus here to regression adjustment.\n\n\n\n\nFigure 1: Simple DAG for the Effect of X on Y where Z Denotes Observed Confounders and U is an Unobserved Confounder\n\n\n\n\n\n\nAlthough adusting for the set of confounders \\(Z\\) is sufficient to identify the total effect of \\(X\\) on \\(Y\\), it would be erronous to assume, as many researchers do, this implies any of the confounders in the adjustment set \\(Z\\) are also themselves causally identified. In fact, based on the DAG in figure 1, it is mathematically impossible to simultaneously identify both \\(X\\) and any variable in the set \\(Z\\) due the biasing paths \\(Z \\longleftarrow U \\longrightarrow Y\\) where \\(U\\) is an unobserved confounder. That is, under ideal conditions regression adjustment can be used to estimate causal effects in the abscence of random assignment. As a general rule, however, it is unlikely other covariates in a regression model may be ascribed a valid causal interpretation without further assumptions that are difficult to defend in practice."
  },
  {
    "objectID": "blog/2022/statistical-adjustment-interpretation/index.html#simulation-study",
    "href": "blog/2022/statistical-adjustment-interpretation/index.html#simulation-study",
    "title": "These Aren’t the Effects You’re Looking For",
    "section": "Simulation Study",
    "text": "Simulation Study\nTo further illustrate why the concept of mutual adjustment is fundamentally flawed, consider the more complex data generation process depicted by the causal graph in figure 2. As in the example above, \\(X\\) is some exposure or treatment of interest, \\(Y\\) is the outcome, \\(\\{Z, W, L, J\\}\\) is a set of measured confounders, and \\(\\{U, V\\}\\) are unobserved confounders.\n\n\n\nFigure 2: DAG for a Hypothetical Data Generation Process\n\n\n\n\n\n\nIf our primary objective is to identify the causal path \\(X \\longrightarrow Y\\), this can be acheived by adjusting for the set \\(\\{Z, L, W, J\\}\\) as illustrated in figure 3.1 Although this set is sufficient to identify the path \\(X \\longrightarrow Y\\), it does not identify other paths such as \\(J \\longrightarrow Y\\) or \\(Z \\longrightarrow Y\\) which are confounded by the biasing paths \\(J \\longleftarrow V \\longrightarrow Y\\) and \\(Z \\longleftarrow U \\longrightarrow Y\\) respectively. If this all seems abstract, you can simply substitute the letters representing nodes in the figure above for theoretical constructs that are more familiar. The important takeaway here is when using statistical adjustment as an empirical strategy, the relationship between treatment and outcome is the path we care about and the adjustment set is a sacrifice we make on the altar of causal identification.\n\n\n\n\nFigure 3: Data Generation Process for the Simulation Study\n\n\n\n\n\n\nThus far I have levied several bold claims, some of which amount to accusing many accomplished scholars of engaging in a practice that effectively amounts to the propagation of pseudo-science. Although I have grounded this argument squarely in the logic of causality, some readers may insist upon further illustration of just how wrong the practice of presenting and interpreting coefficients for nuisance parameters can be. After all, if we are able to justify the assumption the unobserved confounder \\(U\\) is conditionally independent of \\(Z\\), it is possible to jointly identify the causal paths \\(Z \\longrightarrow Y\\) and \\(X \\longrightarrow Y\\) based on the adjustment set \\(\\{L, W, J\\}\\).\nTo demonstrate the magnitude of the problem, I simulate data based on the theoretical process depicted in figure 3, manipulating the path \\(U \\longrightarrow Z\\) to assess the bias in the estimate for the causal effect of \\(Z\\) on \\(Y\\). I also vary the dimensions of the data, considering 2,500, 5,000, and 10,000 observations and repeat the simulation 500 times per cell, resulting in 3,000 unique datasets. To provide a breif overview of the simulation design, I begin by drawing fixed values for the unobserved confounders \\(U\\) and \\(V\\) at 1.0 and 0.5, respectively. The path coefficients \\(\\gamma_{k}\\) for the dependencies between nodes are then drawn from a normal distribution such that \\(\\gamma_{k} \\sim \\mathrm{Normal(0.5, 0.5)}\\) for \\(k \\in \\{1, \\dots, K\\}\\). The treatment propensity \\(\\theta\\) for the exposure \\(X\\) and the measured confounders are then each a function of their respective ancestor nodes and random noise \\(\\sigma \\sim \\mathrm{Normal(0, 0.1)}\\) as follows\n\\[\n\\begin{align}\nZ_{i} &\\sim \\gamma_{5}W + \\gamma_{6}L_{i} + \\delta U + \\sigma_{Z}\\\\\nL_{i} &\\sim \\gamma_{3}U_{i} + \\gamma_{4}V_{i} + \\sigma_{L}\\\\\nJ_{i}&\\sim \\gamma_{2}V + \\sigma_{J}\\\\\nW_{i} &\\sim \\gamma_{1}U + \\sigma_{W}\\\\\n\\end{align}\n\\] and for the observed treatment\n\\[\n\\begin{align}\nX_{i} &\\sim \\mathrm{Bernoulli}(\\theta_{i})\\\\\n\\theta_{i} &= \\mathrm{logit}^{-1}(\\gamma_{7}Z_{i} + \\gamma_{8} W_{i} + \\gamma_{9} J_{i} + \\gamma_{10} L_{i} + \\sigma_{X})\\\\\n\\end{align}\n\\]\n\nwhere the \\(\\delta U\\) in the equation for \\(Z\\) represents the experimental manipulation and \\(\\sigma_{X} \\sim \\mathrm{Normal(0, 0.01)}\\).\n\nFinally, the outcome \\(Y_{i}\\) is a function of a fixed intercept \\(\\alpha\\), coefficients for each parameter \\(\\beta_{k}\\), the unobserved confounders \\(U\\) and \\(V\\), and a random noise term \\(\\sigma\\) as expressed in equation 3\n\n\\[\nY_{i} \\sim \\alpha + \\beta_{1}X_{i} + \\beta_{2}Z_{i} + \\beta_{3}L_{i} + \\beta_{4}W_{i} + \\beta_{5}J_{i} + V + U + \\sigma\n\\tag{3}\\]\nwhere \\(\\alpha = 0.50\\) and \\(\\sigma~\\sim~\\mathrm{Normal}(0, 0.5)\\).\n\nUnder this assumed DGP, the true value of \\(Z\\) should be recoverable if and only if the unobserved confounder \\(U\\) is conditionally independent of \\(Z\\). On the other hand, all of the covariates in the adjustment set \\(\\{J, W, L\\}\\) may be expected to exhibit severe bias due to unobserved confounding. Code for simulating the data in R and Python is shown below.\n\n\n\nR\nPython\n\n\n\n\nCode# Simulated DGP Based on the DAG in Figure 2\nsim_dag_data <- function(N, a, b, cond, conf) {\n  # Coefficients for ancestor nodes\n  g <- rnorm(10, 0.5, 0.5)\n    \n  # Unobserved Confounders U and V\n  V <- conf[1] + rnorm(N, 0, 0.1)\n  U <- conf[2] + rnorm(N, 0, 0.1)\n    \n  # Measured Confounders {Z, L, J, W}\n  W <- g[1] * U + rnorm(N, 0, 0.1)\n  J <- g[2] * V + rnorm(N, 0, 0.1)\n  L <- g[3] * U + g[4] * V + rnorm(N, 0, 0.1)\n  Z <- g[5] * W + (U * cond) + g[6] * L + rnorm(N, 0, 0.1)\n    \n  # Treatment X\n  logit_theta <- g[7] * Z + g[8] * W + g[9] * J + g[10] * L + rnorm(N, 0, 0.01)\n  theta <- exp(logit_theta)/(1 + exp(logit_theta))\n  X <- rbinom(N, size = 1, prob = theta)\n    \n  # Linear Predictor Data Generation Process\n  mu <- b[1] * X + b[2] * Z + b[3] * L + b[4] * J + b[5] * W\n    \n  # Observed Response Y\n  Y <- a + mu + U + V + rnorm(N, 0, 0.2)\n    \n  # Combine everything into a data frame\n  out <- data.table(X, Z, L, J, W, Y)\n\n  # Return just the data table\n  return(out)\n} \n\n\n\n\n# Required dependencies for the DAG data\nfrom numpy.random import normal as rnorm\nfrom numpy.random import uniform as runif\nfrom numpy.random import binomial as rbinom\nfrom numpy import exp, repeat\nfrom polars import DataFrame, Series\n\n# Inverse Logistic Transformation\ndef inv_logit(logit_theta):\n  prob = exp(logit_theta)/(1 + exp(logit_theta))\n  return prob\n\n# Simulated DGP Based on the DAG in Figure 1\ndef sim_dag_data(N, a, b, cond, conf):\n  # Coefficients for ancestor nodes\n  g = rnorm(0.5, 0.5, 10)\n    \n  # Unobserved Confounders U and V\n  V = conf[\"V\"] + rnorm(0, 0.1, N)\n  U = conf[\"U\"] + rnorm(0, 0.1, N)\n    \n  # Measured Confounders {Z, L, J, W}\n  W = g[0] * U + rnorm(0, 0.1, N)\n  J = g[1] * V + rnorm(0, 0.1, N)\n  L = g[2] * U + g[3] * V + rnorm(0, 0.1, N)\n  Z = g[4] * W + (U * cond) + g[5] * L + rnorm(0, 0.1, N)\n    \n  # Treatment X\n  logit_theta = g[6] * Z + g[7] * W + g[8] * J + g[9] * L + rnorm(0, 0.01, N)\n  theta = inv_logit(logit_theta)\n  X = rbinom(n = 1, p = theta, size = N)\n    \n  # Linear Predictor Data Generation Process\n  mu = b[\"X\"] * X + b[\"Z\"] * Z + b[\"L\"] * L + b[\"J\"] * J + b[\"W\"] * W\n    \n  # Observed Response Y\n  Y = a + mu + U + V + rnorm(0, 0.2, N)\n  \n  # Store the Condition\n  cond = Series(repeat(cond, N))\n\n  # Combine everything into a data frame\n  out = {\"X\": X, \"Z\": Z, \"L\": L, \"J\": J, \"W\": W, \"Y\": Y, \"Condition\": cond}\n  return DataFrame(out)\n\n\n\n\nSince this is a Bayesian statistics blog, we’ll specify the model and estimate the parameters using Hamiltonian Monte Carlo (HMC), though the concept outlined above holds regardless of inferential framework and taking a Bayesian approach may in fact be constraining how severe the bias in the parameter estimates can be.2 Our model here takes the following form\n\n\\[\n\\begin{align}\ny_{i} &\\sim \\mathcal{N}(\\mu, \\sigma)\\\\\n\\mu &= \\alpha + X_{n}\\beta_{k} + \\sigma\\\\\n\\text{with priors}\\\\\n\\alpha &\\sim \\mathrm{Normal}(\\bar{y}, ~2\\cdot\\sigma_{y})\\\\\n\\beta_{k} &\\sim \\mathrm{Normal}\\left(0, ~2 \\cdot \\frac{\\sigma_{y}}{\\sigma_{x_{k}}}\\right) ~ \\mathrm{for~} k \\in \\{1,\\dots,K\\}\\\\\n\\sigma &\\sim \\mathrm{Exponential}\\left(\\frac{1}{\\sigma_{y}}\\right)\n\\end{align}\n\\tag{4}\\]\nwhere priors in equation 4 are specified based on the scaling approach outlined in Gelman, Hill, and Vehtari (2021) and thus automatically adjusted to be weakly informative for each of the simulated datasets. We can specify the model in Stan as follows\ndata {\n  int<lower=1> N; // Observations\n  int<lower=1> K; // Population-Level Coefficients\n  vector[N] Y; // Response\n  matrix[N, K] P; // Design Matrix for the Fixed Effects\n  vector[K] truth; // True Values of the Coefficients\n}\n\ntransformed data {\n  // Centering the Design Matrix\n  matrix[N, K] X;  // Centered version of P\n  vector[K] X_means; // Column Means of P\n  vector[K] X_sd; // Column SDs of P\n  for (i in 1:K) {\n    X[, i] = P[, i] - mean(P[, i]);\n    X_means[i] = mean(P[, i]);\n    X_sd[i] = sd(P[, i]);\n  }\n\n  // Data for the Intercept priors\n  real mu_alpha;\n  real sigma_alpha;\n  mu_alpha = mean(Y);\n  sigma_alpha = 2 * sd(Y);\n\n  // Data for the Coefficient priors\n  vector[K] beta_sd;\n  beta_sd = 2 * (sd(Y)/X_sd);\n\n  // Prior for the residual sd\n  real sigma_prior;\n  sigma_prior = 1/sd(Y);\n}\n\nparameters {\n  real alpha; // Intercept for the Centered Predictors\n  vector[K] beta; // Regression Coefficients\n  real<lower = 0> sigma; // Residual Noise\n}\n\nmodel {\n  // Likelihood\n  target += normal_id_glm_lpdf(Y | X, alpha, beta, sigma);\n\n  // Priors on the parameters\n  target += exponential_lpdf(sigma | sigma_prior);\n  target += normal_lpdf(alpha | mu_alpha, sigma_alpha);\n  target += normal_lpdf(beta | 0, beta_sd);\n}\n\ngenerated quantities {\n  // Recover the Non-Centered Intercept and Coefficients\n  real Intercept = alpha - dot_product(beta, X_means);\n\n  // Bias in the Parameter Estimates\n  vector[K] bias;\n  bias = truth - beta;\n}\n\nAlthough the models themselves only take a second or two to fit, repeating the process 3,000 times quickly becomes computationally burdensome. It is possible to side-step this problem by defining functions to prepare the data and fit models in parallel via the furrr package and cmdstanr as shown below. The make_stan_data function prepares the simulated datasets to be passed to Stan while the sim_bayes function fits the models and returns the necessary draws_df object containing the estimated parameters and generated quantities. This approach reduces the wall time for the simulations from 1.5 hours to about thirty minutes.\nFor each model, I run four Markov chains in parallel for 2,000 total iterations per chain with the first 1,000 for each chain discarded after the initial warm-up adaptation stage. The total run time for the simulations under Stan version 2.3.0 is approximately 35 minutes on a Windows 10 desktop computer with an 12-core Ryzen 9 5900X CPU and 128GB of DDR4 memory.\n\n\n\nFunctions\nData Simulation\nEstimation\nPost-Estimation\n\n\n\n# Function for Building the Data to Pass to the Stan Model\nmake_stan_data <- function(data, truth, ...) {\n  \n  # Predictor Positions\n  x_pos <- grep(\"[J-X]|Z\", colnames(data))\n  \n  # Extract the predictor matrix\n  P <- data[, ..x_pos]\n  \n  # Extract the response\n  Y <- data$Y\n  \n  # Prepare the data for use with Stan\n  stan_data <- list(\n    N = nrow(P), # Observations\n    K = ncol(P), # K Predictors\n    Y = Y, # Response\n    P = P, # Design Matrix\n    truth = truth\n  )\n  \n  # Return the list of data\n  return(stan_data)\n}\n\n# Function for fitting the Stan Models in Parallel\nsim_bayes <- function(stan_model, \n                      stan_data,\n                      sampling, \n                      warmup, \n                      seed, \n                      chains,\n                      ...) {\n  \n  # Set the initial number of draws to 0\n  min_draws <- 0\n  \n  # Repeat the run if any of the chains stop unexpectedly\n  while (min_draws < (sampling * chains)) {\n    \n    # Fit the Stan Model\n    sim_fit <- stan_model$sample(\n      data = stan_data,\n      sig_figs = 5,\n      parallel_chains = chains,\n      iter_warmup = warmup,\n      iter_sampling = sampling,\n      max_treedepth = 12,\n      adapt_delta = 0.9,\n      seed = seed,\n      show_messages = FALSE,\n      ...\n    )\n    \n    # Update the check\n    min_draws <- posterior::ndraws(sim_fit$draws())\n  }\n  \n  # Calculate a summary of the draws\n  sim_draws <- sim_fit$draws(format = \"draws_df\")\n  \n  # Return the data frame of draws\n  return(sim_draws)\n}\n\n\n# Load the necessary libraries\npacman::p_load(\n  \"tidyverse\",\n  \"data.table\",\n  \"cmdstanr\",\n  \"posterior\",\n  \"furrr\",\n  install = FALSE # Set this to true to install missing packages\n)\n\n# Set the initial rng seed\nset.seed(2023)\n\n# True Values for the Coefficients\nbetas <- c(-0.5, 0.00, 0.5, 0.00, 0.5)\nnames(betas) <- c(\"X\", \"Z\", \"L\", \"J\", \"W\")\n\n# Simulate 3,000 datasets of varying dimensions \nsim_data_df <- expand.grid(\n  N = c(2.5e3, 5e3, 10e3),\n  delta = c(FALSE, TRUE),\n  rep = 1:500\n) %>%\n  # Nest the data by columns\n  nest(sim_pars = c(delta, N)) %>%\n  # Simulate the datasets\n  mutate(sim_data = map(\n    .x = sim_pars,\n    ~ map2(\n      .x = .x$delta,\n      .y = .x$N,\n      ~ sim_dag_data(\n        N = .y, \n        a = 0.5, \n        b = betas, \n        cond = .x,\n        conf = c(0.5, 1.0)\n      ))\n  )) %>%\n  # Unnest the data dimensions\n  unnest(cols = c(sim_pars, sim_data))\n\n\n# Generate the data to pass to the stan models\nsims_stan_data <- map(\n  .x = sim_data_df$sim_data,\n  ~ make_stan_data(\n    data = .x,\n    truth = betas\n  ))\n\n# Compile the Stan model\nsim_mod <- cmdstan_model(\"bayes-linreg.stan\")\n\n# Parallel computation via furrr\nplan(tweak(multisession, workers = 3))\n\n# Fit models and add the draws to the simulation data frame\nsim_draws_df <- sim_data_df %>% \n  mutate(sim_draws = future_map(\n    .x = sims_stan_data,\n    .f = ~ sim_bayes(\n      stan_data = .x,\n      stan_model = sim_mod,\n      sampling = 1e3,\n      warmup = 1e3,\n      seed = 12345,\n      chains = 4,\n      refresh = 1e3\n    ),\n    .options = furrr_options(\n      scheduling = 1,\n      seed = TRUE,\n      prefix = \"prefix\"\n    ),\n    .progress = TRUE\n  ))\n\n# Back from the future\nplan(sequential)\n\n\n# Parallel computation via furrr\nplan(tweak(multisession, workers = 8))\n\n# Summarize the nested draws_df objects\nsim_draws_df <- sim_draws_df %>% \n  mutate(sim_draws_summ = future_map(\n    .x = sim_draws,\n    .f = ~ summarise_draws(.x, default_summary_measures()),\n    .options = furrr_options(\n      scheduling = 1,\n      seed = TRUE,\n      prefix = \"prefix\"\n    ),\n    .progress = TRUE\n  ))\n\n# Back from the future\nplan(sequential)\n\n# Extract and combine the posterior draws\nsim_draws_combined <- sim_draws_df %>% \n  # Subset the needed columns\n  select(rep:N, sim_draws_summ) %>% \n  # Unnest the draws, this requires about 25GB of memory\n  unnest(cols = sim_draws_summ) %>% \n  # Filter estimates and bias for X and Z\n  filter(str_detect(variable, \"b.*[1-5]\")) %>% \n  # Generate identifiers and labels\n  mutate(\n    # Coefficient or Bias Identifier\n    type = if_else(str_detect(variable, \"beta\"), \"Coefficient\", \"Bias\"),\n    # Manipulated condition\n    condition = if_else(delta == TRUE, \"Z Confounded\", \"Z Unconfounded\"),\n    # Parameter names\n    param = case_when(\n      variable %in% c(\"bias[1]\", \"beta[1]\") ~ \"X\",\n      variable %in% c(\"bias[2]\", \"beta[2]\") ~ \"Z\",\n      variable %in% c(\"bias[3]\", \"beta[3]\") ~ \"L\",\n      variable %in% c(\"bias[4]\", \"beta[4]\") ~ \"J\",\n      variable %in% c(\"bias[5]\", \"beta[5]\") ~ \"W\"\n    ),\n    # True Parameter values\n    truth = case_when(\n      param %in% c(\"L\", \"W\") ~ 0.5,\n      param %in% c(\"Z\", \"J\") ~ 0.0,\n      param == \"X\" ~ -0.5\n    ))\n\n\n\n\nSince most researchers, at least in practice, adhere to dichotomous decision thresholds and test against point nulls, I start here by assessing the coverage rates for the 90% credible intervals for the posterior distribution of each parameter. As table 1 illustrates, the credible intervals capture the true parameter value at or near nominal rates for \\(X\\) and for \\(Z\\) when \\(U\\) is conditionally independent. If, however, \\(U\\) and \\(Z\\) are correlated the 90% credible intervals will virtually always fail to capture the true parameter value. Furthermore, as expected, recovery rates for the parameters \\(W\\), \\(J\\), and \\(L\\) are generally abysmal under either condition and tend to decline as \\(n \\longrightarrow \\infty\\). The practical implication here is that if \\(U\\) and \\(Z\\) are in fact correlated, and we proceed to present and interpret \\(Z\\) as if its respective coefficient is somehow meaningful, we will almost always be wrong. The picture is even more dire for the other parameters which are unlikely to have any meaningful interpretation under either scenario.\n\n\n\n\n\n\nTable 1:  Coverage Probabilities for 90% Bayesian Credible Intervals by Parameter \n \n\n\nZ Confounded\nZ Unconfounded\n\n\n  \n    2,500 \n    5,000 \n    10,000 \n    2,500 \n    5,000 \n    10,000 \n  \n\n\n\n X \n    0.89 \n    0.89 \n    0.91 \n    0.89 \n    0.90 \n    0.89 \n  \n\n Z \n    0.01 \n    0.01 \n    0.00 \n    0.93 \n    0.91 \n    0.90 \n  \n\n L \n    0.16 \n    0.11 \n    0.07 \n    0.06 \n    0.05 \n    0.03 \n  \n\n J \n    0.13 \n    0.07 \n    0.06 \n    0.11 \n    0.08 \n    0.06 \n  \n\n W \n    0.29 \n    0.21 \n    0.15 \n    0.14 \n    0.13 \n    0.09 \n  \n\n\n\n\n\n\nJust how wrong are these parameter estimates likely to be? Here I move beyond simple error probabilities and look more closely at errors of magnitude.3 Conditional on having already committed a Type I error and concluding that our credible interval contains the true parameter value when it in fact does not,4 figure 4 shows the average root mean square error for each parameter in which the 90% credible interval fails to capture the true value. We see that on average the magnitude of bias in covariates can be quite large and in the case both \\(Z\\) and \\(X\\) are jointly identified, the magnitude of bias in the parameters \\(L\\) and \\(W\\) is on average worse than when \\(Z\\) and \\(U\\) are correlated. Nor does this bias decrease as \\(n \\longrightarrow \\infty\\), underscoring the reality that “big data” is not a substitute for experimental design or causal reasoning.\n\n\n\n\nFigure 4: Average Parameter Bias in Models that Do not Recover the True Value\n\n\n\n\n\n\nAs table 1 illustrated, if we present and interpret \\(L\\) or \\(J\\), or \\(W\\) as if they are total effect estimates, we will on average be wrong 88.5%, 91.6%, and 78.4% of the time, respectively. Likewise, if the assumption that \\(U\\) and \\(Z\\) are conditionally independent fails, our chance of being wrong is 99.6%. This makes the practice of reporting and interpreting nuisance parameters in tables–often filled with largely meaningless astrisks–deeply concerning because, at least in principle, the goal of scientific inquiry and research more broadly is to be less wrong.\nThe important takeaway here is anything other than \\(X\\) or whatever your main feature of interest happens to be, is a nuisance parameter and generally should not be presented or interpreted as if its respective coefficient or marginal effect estimate has some causal meaning because the chances your research design is capable of identifying every variable included in a model are virtually guaranteed to be zero. These estimates most certainly are not, as a collegue recently suggested, “a part of your contribution to existing research.” In fact, since presenting and interpreting hopelessly confounded coefficient estimates or marginal effects encourages those reading your work to do the same, those who persist in committing the table 2 fallacy or encourage others to do so are actively harming the pursuit of knowledge in their field by peddling what is in no uncertain terms pseudo-science.\nFinally, for those wondering whether this applies to analyses whose aims are primarily descriptive or exploratory in nature the answer is “yes.” Since identifying relevant confounders is a process that must be informed and justified by theory, the need to adjust for potentially confounding factors itself implies causal aims as does any reporting or reliance on arbitrary decision rules such as “statistical significance” as a means of establishing whether a relationship exists (Wysocki, Lawson, and Rhemtulla 2022). Indeed, outside of a causal framework p-values in the social sciences have no meaning or valid interpretation and thus the practice of reporting, at a minimum, “sign and significance” has always been and continues to be misguided."
  },
  {
    "objectID": "blog/2022/statistical-adjustment-interpretation/index.html#conclusion",
    "href": "blog/2022/statistical-adjustment-interpretation/index.html#conclusion",
    "title": "These Aren’t the Effects You’re Looking For",
    "section": "Conclusion",
    "text": "Conclusion\nThe overarching and unnecessarily long-winded point of this post is that applied researchers should focus on the feature of the world they care about. If one is interested in a relationship between the implementation of gender quotas and women’s representation in government, for example, one should simply focus on estimating the impact of quota adoption on the representation of women in government rather than wasting words opining about political corruption, electoral systems, or some other nuisance parameter.5\n\nOne might attempt to object on the grounds incompetent reviewers often demand otherwise principled researchers engage in poor statistical practices but this is easily solved by placing all relevant tables in the appendix and adhereing to the common sense guideline that one should never present in a table what could be communicated in a graph. This post and the recommendations herein are broadly applicable in both experimental and observational contexts. The problem remains prevelant in both top tier journals and those with less prestige.\nOf course, encouraging researchers to improve their own practices is only half the battle because bad habits and logical fallacies are learned behaviors oweing to the reality that graduate-level statistics in the social sciences is often taught entirely independent of any meaningful causal foundation. Students are instructed to interpret everything with the justification being that “they need experience in interpreting coefficients/marginal effects.” Yet, this has the unintended consequence of instilling in them that such an approach should be taken in their own work and they then go onto to teach their future students those same poor practices. Before long, this results in entire fields in which presumed knowledge rests upon castles of sand and hinders scientific progress."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "A Bayesian Statistics and Data Science Blog",
    "section": "",
    "text": "These Aren’t the Effects You’re Looking For\n\n\n\n\n\nThis blog post provides an overview of the logic of statistical control, the fallacy of mutual adjustment, and a simulation-based illustration of correct and incorrect approaches to the interpretation of multivariable regression models in the social sciences.\n\n\n\n\n\n\nDecember 13, 2022\n\n\nA. Jordan Nafa\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A. Jordan Nafa",
    "section": "",
    "text": "Welcome to my personal website. I am a Quantitative Social Scientist and Teaching Fellow in the Department of Political Science at the University of North Texas. I have five years’ experience working both independently and in collaboration with colleagues to model data and provide insights necessary to answer research questions. My core skills include research design, causal inference, quasi-experimental methods, multilevel analysis, advanced data analytics in R, Stan, and Python, survey research, and applied Bayesian inference.\n\nAt present, my work is focused at the intersection of applied Bayesian statistics and causal inference with a substantive focus on women in politics and comparative political behavior. More information on my background and recent projects can be found on the about and projects sections of the site or my github, respectively. I also write occasional blog posts on applied Bayesian statistics, causal inference, and data science."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Research and Projects",
    "section": "",
    "text": "My current work centers around applied Bayesian statistics and causal inference in the social sciences with a substantive focus on comparative political behavior, descriptive representation, and women in politics."
  },
  {
    "objectID": "projects/index.html#working-papers",
    "href": "projects/index.html#working-papers",
    "title": "Research and Projects",
    "section": "Working Papers",
    "text": "Working Papers\n\nNafa, A. Jordan and Andrew Heiss. “Taking Uncertainty Seriously: Bayesian Marginal Structural Models for Causal Inference in Political Science.” Paper presented at the American Political Science Association’s Annual Meeting in Montreal, Quebec, September 15–18, 2022.   \n\n\nNafa, A. Jordan, Meredith Walsh Niezgoda, P. Deanne Roark, and Valerie Martinez-Ebers. “Stronger Together? Linked Fate and Voter Preferences in the 2020 Election.” Paper presented at the American Political Science Association’s Annual Meeting in Montreal, Quebec, September 15–18, 2022.    \n\n\nNafa, A. Jordan and P. DeAnne Roark. “Broadening the Base? How Female Rebels Impact the Political Transition and Survival of Rebel Parties.” Paper presented at the International Studies Association’s Annual Meeting in Nashville, Tennessee, March 28–April 2, 2022. \n\n\nNafa, A. Jordan. “From Seeing to Believing? How Female Representation Shapes Support for Democracy.” Paper presented at the Southern Political Science Association’s Annual Meeting in San Antonio, Texas, January 13–15, 2022. \n\n\nBenton, Amber Rose and A. Jordan Nafa. “Climate Catastrophes and Environmental Policy Preferences: A Subnational Analysis.” Paper presented at the Southern Political Science Association’s Annual Meeting in San Antonio, Texas, January 13–15, 2022. \n\n\nRoark, P. DeAnne and A. Jordan Nafa. “The Threat from Within: Intrastate Armed Conflict and Female Representation in Democratic Legislatures.” Paper presented at the International Studies Association’s Midwestern division’s annual meeting in St. Louis, Missouri, November 19–21, 2021."
  }
]